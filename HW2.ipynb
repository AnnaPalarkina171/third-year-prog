{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S9NSGuaimp3",
        "colab_type": "text"
      },
      "source": [
        "Нужно написать классы RussianSentence и EnglishSentence. Конструктор получает на вход предложение на соответствующем языке.\n",
        "Атрибуты могут быть любые, подумайте, как вам удобно будет хранить данные о предложении.\n",
        "Оба класса должны реализовывать следующие методы :\n",
        "\n",
        "> get_words() - возвращает список слов\n",
        "\n",
        "\n",
        "> get_lemmas() - возвращает список лемм\n",
        "\n",
        "\n",
        "> get_pos(pos) - принимает на вход название части речи, возвращает все слова этой части речи из предложения в виде списка, в качестве аргумента pos можно передать одну из частей речи из заранее определенного вами набора, одинакового для обоих классов\n",
        "\n",
        "\n",
        "> check_affirm() - возвращает 'Утвердительное'/'Вопросительное'/'Восклицательное' в зависимости от знака препинания на конце (всё что не вопросительное и не восклицательное давайте считать утвердительным)\n",
        "\n",
        "\n",
        "> деструктор, который напечатает сообщение о том, что объект удален\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxTs7GCqrNuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, ToktokTokenizer\n",
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61oELJGSidwY",
        "colab_type": "code",
        "outputId": "24bc12b0-23d8-4c7c-d1a7-8cbaa1a37f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "class  RussianSentence(object):\n",
        "  \"\"\"\n",
        "  Docstring\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, phrase):\n",
        "    \"\"\"\n",
        "    Constructor\n",
        "    \"\"\"\n",
        "    self.phrase  = phrase\n",
        "    \n",
        "\n",
        "  def get_words(self):\n",
        "    \"\"\"\n",
        "    Getting the list of words\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-‘’'\n",
        "    clean_words = [w.strip(punct) for w in word_tokenize(self.phrase)]\n",
        "    for word in clean_words:\n",
        "      if word != '':\n",
        "        words.append(word)\n",
        "\n",
        "    return words\n",
        "\n",
        "  @staticmethod\n",
        "  def get_lemmas(words):\n",
        "    \"\"\"\n",
        "    Getting the list of lemmas\n",
        "    \"\"\"\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "      p = morph.parse(word)\n",
        "      first = p[0]  # первый разбор\n",
        "      lemmas.append(first.normal_form)\n",
        "    return lemmas\n",
        "\n",
        "  @staticmethod\n",
        "  def get_pos(words,pos):\n",
        "    \"\"\"\n",
        "    Getting all the words of given part of speech\n",
        "    \"\"\"\n",
        "    pos_words = []\n",
        "    poss = []\n",
        "    morph = MorphAnalyzer()\n",
        "    for word in words:\n",
        "      p = morph.parse(word)\n",
        "      first = p[0]  # первый разбор\n",
        "      poss.append(first.tag.POS)\n",
        "\n",
        "    all_poses = ['CONJ', 'NOUN', 'NPRO', 'ADJF', 'PREP', 'PRTS', 'ADVB',  'INFN','VERB'] #этот набор одинаковый для обоих классов\n",
        "    if pos not in all_poses:\n",
        "      raise ValueError('Part of speech tag is needed!')\n",
        "    else:\n",
        "      if pos not in poss:\n",
        "        print('There is no such part of speech in the phrase')\n",
        "      else:\n",
        "        i = -1\n",
        "        for pss in poss:\n",
        "          i+=1\n",
        "          if pos == pss:\n",
        "            pos_words.append(words[i])\n",
        "    return pos_words\n",
        " \n",
        "\n",
        "  def check_affirm(self):\n",
        "    \"\"\"\n",
        "    Checking the type of the sentence\n",
        "    \"\"\"\n",
        "    affirmative = ['.','...']\n",
        "    interrogative = ['?']\n",
        "    exclamatory  = ['!']\n",
        "    if self.phrase[-1] == '?':\n",
        "      return 'Interrogative sentence'\n",
        "    if self.phrase[-1] == '!':\n",
        "      return 'Exclamatory sentence'\n",
        "    else:\n",
        "      return 'Affirmative sentence'\n",
        "\n",
        "\n",
        "#Для русского языка\n",
        "if __name__ == \"__main__\":\n",
        "  rs = RussianSentence('Привет, как дела?')\n",
        "  print('Список слов: ',rs.get_words())\n",
        "  words = rs.get_words()\n",
        "  print('Список лемм: ',rs.get_lemmas(words))\n",
        "  pos = 'NOUN'\n",
        "  print('Все слова этой части речи: ' ,rs.get_pos(words,pos))\n",
        "  print(rs.check_affirm())\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Список слов:  ['Привет', 'как', 'дела']\n",
            "Список лемм:  ['привет', 'как', 'дело']\n",
            "Все слова этой части речи:  ['Привет', 'дела']\n",
            "Interrogative sentence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3MifEDb-vlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0310c79a-25f1-42ca-ca4e-2bda656fe225"
      },
      "source": [
        "class EnglishSentence():\n",
        "  \"\"\"\n",
        "  Docstring\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, phrase):\n",
        "    \"\"\"\n",
        "    Constructor\n",
        "    \"\"\"\n",
        "    self.phrase  = phrase\n",
        "    \n",
        "\n",
        "  def get_words(self):\n",
        "    \"\"\"\n",
        "    Getting the list of words\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-‘’'\n",
        "    clean_words = [w.strip(punct) for w in word_tokenize(self.phrase)]\n",
        "    for word in clean_words:\n",
        "      if word != '':\n",
        "        words.append(word)\n",
        "\n",
        "    return words\n",
        "\n",
        "  @staticmethod\n",
        "  def get_lemmas(words):\n",
        "    \"\"\"\n",
        "    Getting the list of lemmas\n",
        "    \"\"\"\n",
        "    lemmas = []\n",
        "    wnl = WordNetLemmatizer()\n",
        "    for word in words:\n",
        "      lemmas.append(wnl.lemmatize(word))\n",
        "    return lemmas\n",
        "    \n",
        "\n",
        "  @staticmethod\n",
        "  def get_pos(words,pos):\n",
        "    \"\"\"\n",
        "    Getting all the words of given part of speech\n",
        "    \"\"\"\n",
        "    all_poses = ['WRB','IN','PRP','VB','VBN','DT','NN','VBZ','CC','RB','VBG','MD','NNS','TO','WDT','JJS','JJ'] \n",
        "    pos_words = []\n",
        "    poss = []\n",
        "    for word in words:\n",
        "      wt = word_tokenize(word)\n",
        "      poss.append(nltk.pos_tag(wt)[0][1])\n",
        "\n",
        "    if pos not in all_poses:\n",
        "      raise ValueError('Part of speech tag is needed!')\n",
        "    else:\n",
        "      if pos not in poss:\n",
        "        print('There is no such part of speech in the phrase')\n",
        "      else:\n",
        "        i = -1\n",
        "        for pss in poss:\n",
        "          i+=1\n",
        "          if pos == pss:\n",
        "            pos_words.append(words[i])\n",
        "    \n",
        "    return pos_words\n",
        " \n",
        "\n",
        "  def check_affirm(self):\n",
        "    \"\"\"\n",
        "    Checking the type of the sentence\n",
        "    \"\"\"\n",
        "    affirmative = ['.','...']\n",
        "    interrogative = ['?']\n",
        "    exclamatory  = ['!']\n",
        "    if self.phrase[-1] == '?':\n",
        "      return 'Interrogative sentence'\n",
        "    if self.phrase[-1] == '!':\n",
        "      return 'Exclamatory sentence'\n",
        "    else:\n",
        "      return 'Affirmative sentence'\n",
        "\n",
        "#для английского языка\n",
        "if __name__ == \"__main__\":\n",
        "  es = EnglishSentence('Hello, how are you?')\n",
        "  print('Список слов: ',es.get_words())\n",
        "  words = es.get_words()\n",
        "  print('Список лемм: ',es.get_lemmas(words))\n",
        "  pos = 'NN'\n",
        "  print('Все слова этой части речи: ' ,es.get_pos(words,pos))\n",
        "  print(es.check_affirm())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Список слов:  ['Hello', 'how', 'are', 'you']\n",
            "Список лемм:  ['Hello', 'how', 'are', 'you']\n",
            "Все слова этой части речи:  ['Hello']\n",
            "Interrogative sentence\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}